{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e78c487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import textwrap\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd419556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              question  \\\n",
      "0    Postgresql allows adding comments to objects s...   \n",
      "1    Postgresql allows adding comments to objects s...   \n",
      "2    I was doing some work in scipy and a conversat...   \n",
      "3    I was doing some work in scipy and a conversat...   \n",
      "4    Can a permutation matrix ($P$) be used to chan...   \n",
      "..                                                 ...   \n",
      "515  Let $x,y,z$ be positive real numbers such that...   \n",
      "516  Some people say that it's awful that humans ea...   \n",
      "517  Some people say that it's awful that humans ea...   \n",
      "518  I just started working at a company that doesn...   \n",
      "519  I just started working at a company that doesn...   \n",
      "\n",
      "                                                answer true_label  \\\n",
      "0    All comments are stored in pg_description To g...      human   \n",
      "1    To retrieve all tables along with their respec...         ai   \n",
      "2    Let the CDF $F$ equal $1-1/n$ at the integers ...      human   \n",
      "3    0 A non-negative discrete random variable can ...         ai   \n",
      "4    Hint: The rank of a matrix is the number of li...      human   \n",
      "..                                                 ...        ...   \n",
      "515  Since this is a symmetric expression in $x,y,z...         ai   \n",
      "516  The answer to your question is yes it is certa...      human   \n",
      "517  Your question is a classic example of philosop...         ai   \n",
      "518  Why using sharepoint as a sorce control is stu...      human   \n",
      "519  1.  **Lack of Version Control**: SharePoint do...         ai   \n",
      "\n",
      "    predicted_label     score  temperature  top_p  top_k  repeat_penalty  \n",
      "0             human  0.926316          0.8   0.95     40             1.1  \n",
      "1                ai  0.829268          0.8   0.95     40             1.1  \n",
      "2             human  0.985714          0.8   0.95     40             1.1  \n",
      "3             human  0.853741          0.8   0.95     40             1.1  \n",
      "4             human  0.939394          0.8   0.95     40             1.1  \n",
      "..              ...       ...          ...    ...    ...             ...  \n",
      "515           human  0.992032          0.8   1.00     40             1.1  \n",
      "516           human  1.026882          0.8   1.00     40             1.1  \n",
      "517              ai  0.791209          0.8   1.00     40             1.1  \n",
      "518           human  0.928571          0.8   1.00     40             1.1  \n",
      "519              ai  0.546632          0.8   1.00     40             1.1  \n",
      "\n",
      "[520 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "def normalize_label(label):\n",
    "    \"\"\"\n",
    "    Normalize prediction labels to consistent format.\n",
    "    \"\"\"\n",
    "    if pd.isna(label):\n",
    "        return 'unknown'\n",
    "    \n",
    "    label_str = str(label).lower().strip()\n",
    "    \n",
    "    if 'human' in label_str:\n",
    "        return 'human'\n",
    "    elif 'ai' in label_str or 'generated' in label_str:\n",
    "        return 'ai'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "def reorganize_meta_param_csvs(input_files):\n",
    "    \"\"\"\n",
    "    Reorganize multiple meta-parameter CSVs into a single clean DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - input_files: list of CSV file paths\n",
    "\n",
    "    Returns:\n",
    "    - df_clean: reorganized combined DataFrame\n",
    "    \"\"\"\n",
    "    reorganized_data = []\n",
    "\n",
    "    for file in input_files:\n",
    "        # Use quoting=1 (QUOTE_ALL) or quoting=3 (QUOTE_MINIMAL) to handle quoted fields properly\n",
    "        # on_bad_lines='skip' helps with malformed rows\n",
    "        df = pd.read_csv(file, encoding='utf8', quotechar='\"', escapechar=None, on_bad_lines='warn')\n",
    "        \n",
    "        # Check for any rows where key columns are NaN (indicates parsing issues)\n",
    "        missing_data = df[df['question'].isna() | df['answer'].isna()]\n",
    "        if len(missing_data) > 0:\n",
    "            print(f\"Warning: {len(missing_data)} rows have missing question or answer data\")\n",
    "        \n",
    "        # Iterate through each row once\n",
    "        for idx, row in df.iterrows():\n",
    "            # Human answer\n",
    "            reorganized_data.append({\n",
    "                'question': row['question'],\n",
    "                'answer': row['answer'],\n",
    "                'true_label': 'human',\n",
    "                'predicted_label': normalize_label(row['answer_detection_prediction']),\n",
    "                'score': row['answer_detection_score'],\n",
    "                'temperature': row['temperature'],\n",
    "                'top_p': row['top_p'],\n",
    "                'top_k': row['top_k'],\n",
    "                'repeat_penalty': row['repeat_penalty']\n",
    "            })\n",
    "            \n",
    "            # AI answer\n",
    "            reorganized_data.append({\n",
    "                'question': row['question'],\n",
    "                'answer': row['question_answer_ai'],\n",
    "                'true_label': 'ai',\n",
    "                'predicted_label': normalize_label(row['question_answer_ai_detection_prediction']),\n",
    "                'score': row['question_answer_ai_detection_score'],\n",
    "                'temperature': row['temperature'],\n",
    "                'top_p': row['top_p'],\n",
    "                'top_k': row['top_k'],\n",
    "                'repeat_penalty': row['repeat_penalty']\n",
    "            })\n",
    "\n",
    "    df_clean = pd.DataFrame(reorganized_data)\n",
    "    \n",
    "    return df_clean\n",
    "    \n",
    "    \n",
    "file_list = [\n",
    "    \"datasets/output_param_20_binoculars_default.csv\",\n",
    "    \"datasets/output_param_20_binoculars_temperature0.0.csv\",\n",
    "    # \"datasets/output_param_20_binoculars_top_k5.csv\",\n",
    "    \"datasets/output_param_20_binoculars_top_p0.6.csv\",\n",
    "    # \"datasets/output_param_1_binoculars_test.csv\"\n",
    "]\n",
    "df_clean = reorganize_meta_param_csvs(file_list)\n",
    "print(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4f6d7e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>top_p</th>\n",
       "      <th>top_k</th>\n",
       "      <th>repeat_penalty</th>\n",
       "      <th>AUROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.9550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.9875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.60</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.9925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.9725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.9425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    temperature  top_p  top_k  repeat_penalty   AUROC\n",
       "0           0.0   0.95     40             1.1  0.9550\n",
       "1           0.2   0.95     40             1.1  1.0000\n",
       "2           0.5   0.95     40             1.1  0.9875\n",
       "3           0.8   0.60     40             1.1  0.9925\n",
       "4           0.8   0.90     40             1.1  0.9900\n",
       "5           0.8   0.95     40             1.0  0.9475\n",
       "6           0.8   0.95     40             1.1  0.9725\n",
       "7           0.8   0.95     40             1.2  0.8125\n",
       "8           0.8   0.95     40             1.5  0.5850\n",
       "9           0.8   1.00     40             1.1  0.9425\n",
       "10          1.0   0.95     40             1.1  0.9400\n",
       "11          1.4   0.95     40             1.1  0.8300\n",
       "12          2.0   0.95     40             1.1  0.8525"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['true_binary'] = df_clean['true_label'].map({'human': 1, 'ai': 0})\n",
    "\n",
    "# Group by metaparameters\n",
    "grouped = df_clean.groupby(['temperature', 'top_p', 'top_k', 'repeat_penalty'])\n",
    "\n",
    "# Calculate AUROC for each group\n",
    "results = []\n",
    "for name, group in grouped:\n",
    "    try:\n",
    "        auroc = roc_auc_score(group['true_binary'], group['score'])\n",
    "    except ValueError:\n",
    "        auroc = None  # Handle cases with only one class\n",
    "    results.append({\n",
    "        'temperature': name[0],\n",
    "        'top_p': name[1],\n",
    "        'top_k': name[2],\n",
    "        'repeat_penalty': name[3],\n",
    "        'AUROC': auroc\n",
    "    })\n",
    "\n",
    "# Convert results to a dataframe\n",
    "auroc_results = pd.DataFrame(results)\n",
    "auroc_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
