{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e78c487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import textwrap\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd419556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              question  \\\n",
      "0    Postgresql allows adding comments to objects s...   \n",
      "1    Postgresql allows adding comments to objects s...   \n",
      "2    I was doing some work in scipy and a conversat...   \n",
      "3    I was doing some work in scipy and a conversat...   \n",
      "4    Can a permutation matrix ($P$) be used to chan...   \n",
      "..                                                 ...   \n",
      "715  Let $x,y,z$ be positive real numbers such that...   \n",
      "716  Some people say that it's awful that humans ea...   \n",
      "717  Some people say that it's awful that humans ea...   \n",
      "718  I just started working at a company that doesn...   \n",
      "719  I just started working at a company that doesn...   \n",
      "\n",
      "                                                answer true_label  \\\n",
      "0    All comments are stored in pg_description To g...      human   \n",
      "1    You can use the `pg_catalog.obj_description` f...         ai   \n",
      "2    Let the CDF $F$ equal $1-1/n$ at the integers ...      human   \n",
      "3    1. Consider the random variable $X$ with proba...         ai   \n",
      "4    Hint: The rank of a matrix is the number of li...      human   \n",
      "..                                                 ...        ...   \n",
      "715  Since this is a symmetric expression in $x,y,z...         ai   \n",
      "716  The answer to your question is yes it is certa...      human   \n",
      "717  Your question is a classic example of philosop...         ai   \n",
      "718  Why using sharepoint as a sorce control is stu...      human   \n",
      "719  1.  **Lack of Version Control**: SharePoint do...         ai   \n",
      "\n",
      "    predicted_label     score  temperature  top_p  top_k  repeat_penalty  \n",
      "0             human  0.926316          0.0   0.95     40             1.1  \n",
      "1                ai  0.656425          0.0   0.95     40             1.1  \n",
      "2             human  0.985714          0.0   0.95     40             1.1  \n",
      "3                ai  0.842975          0.0   0.95     40             1.1  \n",
      "4             human  0.939394          0.0   0.95     40             1.1  \n",
      "..              ...       ...          ...    ...    ...             ...  \n",
      "715           human  1.211679          0.8   0.95     40             1.6  \n",
      "716           human  1.026882          0.8   0.95     40             1.6  \n",
      "717           human  1.226316          0.8   0.95     40             1.6  \n",
      "718           human  0.928571          0.8   0.95     40             1.6  \n",
      "719              ai  0.796954          0.8   0.95     40             1.6  \n",
      "\n",
      "[720 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "def normalize_label(label):\n",
    "    \"\"\"\n",
    "    Normalize prediction labels to consistent format.\n",
    "    \"\"\"\n",
    "    if pd.isna(label):\n",
    "        return 'unknown'\n",
    "    \n",
    "    label_str = str(label).lower().strip()\n",
    "    \n",
    "    if 'human' in label_str:\n",
    "        return 'human'\n",
    "    elif 'ai' in label_str or 'generated' in label_str:\n",
    "        return 'ai'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "def reorganize_meta_param_csvs(input_files):\n",
    "    \"\"\"\n",
    "    Reorganize multiple meta-parameter CSVs into a single clean DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - input_files: list of CSV file paths\n",
    "\n",
    "    Returns:\n",
    "    - df_clean: reorganized combined DataFrame\n",
    "    \"\"\"\n",
    "    reorganized_data = []\n",
    "\n",
    "    for file in input_files:\n",
    "        # Use quoting=1 (QUOTE_ALL) or quoting=3 (QUOTE_MINIMAL) to handle quoted fields properly\n",
    "        # on_bad_lines='skip' helps with malformed rows\n",
    "        df = pd.read_csv(file, encoding='utf8', quotechar='\"', escapechar=None, on_bad_lines='warn')\n",
    "        \n",
    "        # Check for any rows where key columns are NaN (indicates parsing issues)\n",
    "        missing_data = df[df['question'].isna() | df['answer'].isna()]\n",
    "        if len(missing_data) > 0:\n",
    "            print(f\"Warning: {len(missing_data)} rows have missing question or answer data\")\n",
    "        \n",
    "        # Iterate through each row once\n",
    "        for idx, row in df.iterrows():\n",
    "            # Human answer\n",
    "            reorganized_data.append({\n",
    "                'question': row['question'],\n",
    "                'answer': row['answer'],\n",
    "                'true_label': 'human',\n",
    "                'predicted_label': normalize_label(row['answer_detection_prediction']),\n",
    "                'score': row['answer_detection_score'],\n",
    "                'temperature': row['temperature'],\n",
    "                'top_p': row['top_p'],\n",
    "                'top_k': row['top_k'],\n",
    "                'repeat_penalty': row['repeat_penalty']\n",
    "            })\n",
    "            \n",
    "            # AI answer\n",
    "            reorganized_data.append({\n",
    "                'question': row['question'],\n",
    "                'answer': row['question_answer_ai'],\n",
    "                'true_label': 'ai',\n",
    "                'predicted_label': normalize_label(row['question_answer_ai_detection_prediction']),\n",
    "                'score': row['question_answer_ai_detection_score'],\n",
    "                'temperature': row['temperature'],\n",
    "                'top_p': row['top_p'],\n",
    "                'top_k': row['top_k'],\n",
    "                'repeat_penalty': row['repeat_penalty']\n",
    "            })\n",
    "\n",
    "    df_clean = pd.DataFrame(reorganized_data)\n",
    "    \n",
    "    return df_clean\n",
    "    \n",
    "    \n",
    "file_list = [\n",
    "    # \"datasets/output_param_20_binoculars_default.csv\",\n",
    "    \"datasets/output_param_20_binoculars_temperature0.0.csv\",\n",
    "    \"datasets/output_param_20_binoculars_top_k5.csv\",\n",
    "    \"datasets/output_param_20_binoculars_top_p0.6.csv\",\n",
    "    \"datasets/output_param_20_binoculars_repeat_penalty1.0.csv\",\n",
    "]\n",
    "df_clean = reorganize_meta_param_csvs(file_list)\n",
    "print(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f6d7e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>top_p</th>\n",
       "      <th>top_k</th>\n",
       "      <th>repeat_penalty</th>\n",
       "      <th>AUROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.6775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    temperature  top_p  top_k  repeat_penalty   AUROC\n",
       "7           0.8   0.95     40             1.0  0.9475\n",
       "8           0.8   0.95     40             1.2  0.8125\n",
       "9           0.8   0.95     40             1.3  0.6625\n",
       "10          0.8   0.95     40             1.4  0.6775\n",
       "11          0.8   0.95     40             1.5  0.5850\n",
       "12          0.8   0.95     40             1.6  0.4925"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['true_binary'] = df_clean['true_label'].map({'human': 1, 'ai': 0})\n",
    "\n",
    "# Group by metaparameters\n",
    "grouped = df_clean.groupby(['temperature', 'top_p', 'top_k', 'repeat_penalty'])\n",
    "\n",
    "# Calculate AUROC for each group\n",
    "results = []\n",
    "for name, group in grouped:\n",
    "    try:\n",
    "        auroc = roc_auc_score(group['true_binary'], group['score'])\n",
    "    except ValueError:\n",
    "        auroc = None  # Handle cases with only one class\n",
    "    results.append({\n",
    "        'temperature': name[0],\n",
    "        'top_p': name[1],\n",
    "        'top_k': name[2],\n",
    "        'repeat_penalty': name[3],\n",
    "        'AUROC': auroc\n",
    "    })\n",
    "\n",
    "# Convert results to a dataframe\n",
    "auroc_results = pd.DataFrame(results)\n",
    "auroc_results[auroc_results['repeat_penalty'] != 1.1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
